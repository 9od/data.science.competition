{"cells":[{"metadata":{},"cell_type":"markdown","source":"FE_6 \ninteraction term\nconcat 변수 + freq encoding\nbinary sum 변수 + freq encoding"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport random\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import log_loss\nimport lightgbm as lgb\nfrom datetime import datetime, timedelta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tr_vl_split(train_df, num, seed):    \n    '''\n    train / validation split 함수\n    train 에 모든 label이 최소 한번은 등장 & train과 validation의 id는 겹치지 않도록 split함.\n    \n    train_df : train 데이터\n    num : label 당 몇개의 id를 뽑을 것이냐.\n    seed = random seed\n    \n    '''\n    \n    np.random.seed(seed)\n    \n    valid_id = []\n    vc = train[['id','label']].drop_duplicates()['label'].value_counts()\n    temp = list(vc[vc > num].index)\n    for a in temp:\n        id_list = list(train_df[train_df['label'] == a]['id'])\n        valid_id += random.sample(id_list,num)\n    \n    train_id = list(set(train_df['id']) - set(valid_id))\n    \n    x_tr_ = train[train['id'].isin(train_id)]\n    y_tr_ = train_label[train['id'].isin(train_id)]\n\n    x_vl_ = train[~train['id'].isin(train_id)]\n    y_vl_ = train_label[~train['id'].isin(train_id)]\n    \n    return x_tr_, y_tr_, x_vl_, y_vl_ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def target_mode_encoding(col,tr,vl,tst):\n\n    temp = tr.groupby([col])['label'].agg(lambda x:x.value_counts().index[0]).to_dict()\n    \n    tr[col+'_mode_encoding'] = tr[col].map(temp)\n    vl[col+'_mode_encoding'] = vl[col].map(temp)\n    tst[col+'_mode_encoding'] = tst[col].map(temp)\n    \n    return tr, vl, tst","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_pickle('/kaggle/input/15th-data60sec/train_data.pickle/train_data.pickle')\ntest = pd.read_pickle('/kaggle/input/15th-data60sec/test_data.pickle/test_data.pickle')\ntrain_label = train['label']\n\nvar_list = pd.read_csv('/kaggle/input/15th-data60sec/var_type_list.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"etc_var = list(var_list[var_list['type'] == 'etc']['var'])\nnum_var = list(var_list[var_list['type'] == 'num']['var'])\nbin_var = list(var_list[var_list['type'] == 'bin']['var'])\ncat_var = list(var_list[var_list['type'] == 'cat']['var'])\n\nvar_list = etc_var + num_var + bin_var + cat_var\n\ntrain_label = train_label[train['time'] >= 10].reset_index(drop=True)\ntrain = train.loc[(train['time'] >= 10),var_list].reset_index(drop=True)\ntest = test.loc[(test['time'] >= 10),list(set(var_list) - set(['label']))].reset_index(drop=True)\n\n\nall = pd.concat([train,test],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import_var = ['V3616','V0081','V3324','V3615','V2855','V2859','V1821','V1818','V3098',\n 'V3461','V4505','V1820','V2861','V2860','V1819','V3432','V2586','V2854',\n 'V4743','V4824','V3103','V2853','V4495','V2076','V4525']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eng_var = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical 변수 중 가까이 위치한 변수들 concat\n\nconcat_var = [['V0050','V0051'],['V0469','V0471','V0472'],['V0529','V0530','V0532'],['V0731','V0733','V0735'],['V4502','V4504'],['V4526','V4527']]\n\nfor a in tqdm(concat_var):\n    \n    colnm = '_'.join(a + ['concat'])\n    temp = pd.Series(np.repeat('',len(all)))\n    \n    for col in a:\n        temp2 = all[col].astype(str)\n        temp = temp.str.cat(temp2)\n        \n        all[colnm] = pd.factorize(temp)[0]\n        \neng_var += [a for a in all.columns if 'concat' in a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bin_of_bin = pd.Series(all[bin_var].columns[all[bin_var].max() == 1].to_list())\n\nbin_of_bin_series = pd.Series([int(a.replace('V','')[:2]) for a in list(bin_of_bin)])\n\n# V0000~V10000 / V1001 ~ V2000 / V2001 ~ V3000 / V3001 ~ V4000 / V4001 ~ V5000 으로 만든거\nfor i in tqdm(range(5)):\n    cols = list(bin_of_bin[(bin_of_bin_series >= (i*10 + 1)) & (bin_of_bin_series < (i+1)*10 + 1)])\n    all['V_index_'+str(i*10)] = all[cols].sum(axis=1)        \n\nall['V_index_all'] = all[bin_of_bin].sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical 변수와 binary concat 변수의 frequency encoding\nfor col in tqdm(cat_var + [a for a in all.columns if 'concat' in a] + [a for a in all.columns if 'V_index' in a]):\n    temp = all.groupby(col)['id'].count().to_dict()\n    all[col+'_freq'] = all[col].map(temp)\n    del temp\n    \neng_var += [a for a in all.columns if 'freq' in a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 변수 중요도에서 상위 5개 변수의 interaction 변수\nfor i,col1 in tqdm(enumerate(import_var[:5])):\n    for i2 in range(i+1,5):\n        all[col1+'*'+import_var[:5][i2]] = all[col1] * all[import_var[:5][i2]]\n        all[col1+'/'+import_var[:5][i2]] = all[col1] / all[import_var[:5][i2]]\n        all[col1+'+'+import_var[:5][i2]] = all[col1] + all[import_var[:5][i2]]\n        all[col1+'-'+import_var[:5][i2]] = all[col1] - all[import_var[:5][i2]]\n        \neng_var += [a for a in all.columns if '+' in a]\neng_var += [a for a in all.columns if '/' in a]\neng_var += [a for a in all.columns if '*' in a]\neng_var += [a for a in all.columns if '-' in a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = all[~all['label'].isnull()].reset_index(drop=True).drop(columns = ['time'])\ntest = all[all['label'].isnull()].reset_index(drop=True).drop(columns = ['time','label'])\n\ndel all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tr, y_tr, x_vl, y_vl = tr_vl_split(train, 2, seed = 1995)\n\nprint('train shape :',x_tr.shape)\nprint('validation shape :',x_vl.shape)\nprint('test shape :', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for col in tqdm(bin_var + cat_var):\n#     x_tr, x_vl, test = target_mode_encoding(col,x_tr,x_vl,test)\n    \n# eng_var += [a for a in list(x_tr) if 'mode' in a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nx_tr = x_tr.groupby('id').rolling(window = 5).mean().drop(columns = ['id']).reset_index().drop(columns = ['level_1']).dropna().reset_index(drop=True)\nx_vl = x_vl.groupby('id').rolling(window = 5).mean().drop(columns = ['id']).reset_index().drop(columns = ['level_1']).dropna().reset_index(drop=True)\n\ny_tr = x_tr['label']\ny_vl = x_vl['label']\n\ntest = test.groupby('id').rolling(window = 5).mean().drop(columns = ['id']).reset_index().drop(columns = ['level_1']).dropna().reset_index(drop=True)\ntest_id = test['id']\n\nvar_model = list(set(x_tr.columns) & set(test.columns) - set(['id']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nlgb_tr = lgb.Dataset(x_tr[var_model], label=y_tr)\nlgb_vl = lgb.Dataset(x_vl[var_model], label=y_vl)\n\nwatchlist_1 = [lgb_tr, lgb_vl]\nwatchlist_2 = [lgb_vl, lgb_tr]\n\nparams = {\n    \"objective\": \"multiclass\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 40,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"multiclass\",\n    \"num_class\" : 198\n}\n\nlgb_model = lgb.train(params, train_set=lgb_tr, num_boost_round=1000, valid_sets=watchlist_1, verbose_eval=100, early_stopping_rounds=100)\n\nprediction = pd.DataFrame(lgb_model.predict(test[var_model]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(lgb_model,max_num_features = 25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_now = datetime.now() + timedelta(hours = 9)\nsubmission_name = str(time_now)[:16] + '_submission.csv'\nsub = pd.concat([pd.DataFrame(test_id),prediction],axis=1).groupby('id').mean().reset_index()\nsub.to_csv(submission_name,index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}
{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport random\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import log_loss\nimport lightgbm as lgb\nfrom datetime import datetime","execution_count":44,"outputs":[{"output_type":"stream","text":"/kaggle/input/15th-data60sec/var_list.csv\n/kaggle/input/15th-data60sec/train_label.csv\n/kaggle/input/15th-data60sec/test_data.pickle/test_data.pickle\n/kaggle/input/15th-data60sec/train_data.pickle/train_data.pickle\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_pickle('/kaggle/input/15th-data60sec/train_data.pickle/train_data.pickle')\ntest = pd.read_pickle('/kaggle/input/15th-data60sec/test_data.pickle/test_data.pickle')\ntrain_label = train['label']\n\nvar_list = list(pd.read_csv('/kaggle/input/15th-data60sec/var_list.csv')['var'])","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_list = list(reversed(sorted(list(set(var_list) - set(train.columns[train.isna().any()].tolist() + test.columns[test.isna().any()].tolist())))))\n\ntrain = train.loc[(train['time'] >= 10),var_list].reset_index(drop=True)\ntest = test.loc[(test['time'] >= 10),list(set(var_list) - set(['label']))].reset_index(drop=True)\n\nprint(train[var_list].shape)\nprint(test[list(set(var_list) - set(['label']))].shape)","execution_count":3,"outputs":[{"output_type":"stream","text":"(41400, 2545)\n(36000, 2544)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"all = pd.concat([train,test],axis=0).reset_index(drop=True)\nall_value_cnt = all.nunique()","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"히스토그램을 보면 알 수 있듯이, numeric과 categorical이 명확하게 나눠진다 "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(all_value_cnt,bins = 100)\nplt.show()","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_var = list(all_value_cnt[(all_value_cnt < 11) & (all_value_cnt > 2)].index)\nbin_var = list(all_value_cnt[all_value_cnt == 2].index)\nnum_var = list(set(var_list) - set(cat_var) - set(bin_var) - set(['label','id','time']))\netc_var = ['label','id','time']\n\nprint('# of binary feature :',len(bin_var))\nprint('# of categorical feature :',len(cat_var))\nprint('# of numeric feature :',len(num_var))\nprint('# of etc feature :',len(etc_var))","execution_count":6,"outputs":[{"output_type":"stream","text":"# of binary feature : 243\n# of categorical feature : 92\n# of numeric feature : 2207\n# of etc feature : 3\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_of_num_var = all[num_var].mean().reset_index().rename(columns = {'index' : 'var', 0 : 'mean'})\n\nkmeans = MiniBatchKMeans(n_clusters = 50, batch_size = 10000).fit(mean_of_num_var['mean'].values.reshape(-1,1))\nmean_of_num_var['group'] = kmeans.predict(mean_of_num_var['mean'].values.reshape(-1,1))\nmean_of_num_var.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"     var       mean  group\n0  V0395  34.743142     40\n1  V0162  37.330016     40\n2  V1084   0.069716     22\n3  V1249  18.713387      0\n4  V2994  40.053344     49","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var</th>\n      <th>mean</th>\n      <th>group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V0395</td>\n      <td>34.743142</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V0162</td>\n      <td>37.330016</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V1084</td>\n      <td>0.069716</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>V1249</td>\n      <td>18.713387</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>V2994</td>\n      <td>40.053344</td>\n      <td>49</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### PCA를 통해 numeric 변수들의 차원을 축소한다\n- numeric group 별로 차원축소 실시\n- group 별로 1/10로 개수를 줄인다\n- group 별로 하는 이유는 변수 group 별 분포를 더 잘 살리기 위해서"},{"metadata":{},"cell_type":"markdown","source":"현재 변수 분류\n- binary\n- categorical\n- num\n    - pca\n        - group의 value cnt가 50 넘는 그룹만\n    - not_pca\n- etc\n    - id\n    - time\n    - label"},{"metadata":{"trusted":true},"cell_type":"code","source":"grp_cnt = mean_of_num_var['group'].value_counts()\npca_var = []\npcDF = pd.DataFrame()\n\nfor a in tqdm(grp_cnt[grp_cnt > 50].index.tolist()):\n    target_var = mean_of_num_var[mean_of_num_var['group'] == a]['var'].tolist()\n    pca_var += target_var\n    \n    data = all[target_var]\n    for b in target_var:\n        data[b] = StandardScaler().fit_transform(data[b].values.reshape(-1,1))\n    \n    pca_var_nm = ['group_'+str(a)+'_pc'+str(c+1) for c in range(int(len(target_var)/10))]\n    \n    pca = PCA(n_components = int(len(target_var)/10))\n    principalComponents = pca.fit_transform(data.values)\n    pcDF = pd.concat([pcDF,pd.DataFrame(data = principalComponents,\n                columns = pca_var_nm)], axis = 1)\n    \nprint('pca result data shape :', pcDF.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"100%|██████████| 10/10 [00:15<00:00,  1.59s/it]","name":"stderr"},{"output_type":"stream","text":"pca result data shape : (77400, 180)\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_pca_var = list(set(mean_of_num_var['var'].unique()) - set(pca_var))\nnot_pca_train = all.loc[~all['label'].isnull(), not_pca_var].reset_index(drop = True)\nnot_pca_test = all.loc[all['label'].isnull(), not_pca_var].reset_index(drop = True)\n\nprint(not_pca_train.shape)\nprint(not_pca_test.shape)\n\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([train[['label','id']], train[bin_var + cat_var + not_pca_var], pcDF.iloc[:train.shape[0],]],axis=1)\ntest = pd.concat([test[['id']], test[bin_var + cat_var + not_pca_var], pcDF.iloc[train.shape[0]:,].reset_index(drop=True)],axis=1)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain = train.groupby('id').rolling(window = 3).mean().drop(columns = ['id']).reset_index().drop(columns = ['level_1']).dropna().reset_index(drop=True)\ntrain_label = train['label']\ntrain_id = train['id']\n\ntest = test.groupby('id').rolling(window = 3).mean().drop(columns = ['id']).reset_index().drop(columns = ['level_1']).dropna().reset_index(drop=True)\ntest_id = test['id']\n\nvar_model = list(set(train.columns) & set(test.columns) - set(['id']))","execution_count":37,"outputs":[{"output_type":"stream","text":"CPU times: user 33.8 s, sys: 959 ms, total: 34.8 s\nWall time: 34.8 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"        id  label  V0241  V0242  V0244  V0295  V0301  V0650  V0661  V0965  \\\n0        0  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n1        0  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n2        0  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n3        0  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n4        0  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n39739  827  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n39740  827  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n39741  827  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n39742  827  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n39743  827  110.0    0.0    1.0    0.0    0.0    0.0    1.0    1.0    0.0   \n\n       ...  group_29_pc3  group_29_pc4  group_29_pc5  group_29_pc6  \\\n0      ...     -0.026310     -0.046308      0.056537      0.085118   \n1      ...     -0.033793      0.022892      0.057257     -0.274694   \n2      ...     -0.045547     -0.053404      0.044242     -0.013962   \n3      ...     -0.050546     -0.019396      0.053363     -0.143665   \n4      ...     -0.061628     -0.037183      0.058138     -0.096996   \n...    ...           ...           ...           ...           ...   \n39739  ...     -0.560465     -0.072883      0.041725     -0.188920   \n39740  ...     -0.568635     -0.022889      0.037029     -0.589832   \n39741  ...     -0.550188     -0.089338      0.122138     -0.246961   \n39742  ...     -0.545558     -0.138585      0.155958     -0.075894   \n39743  ...     -0.561588     -0.172648      0.143120      0.132126   \n\n       group_26_pc1  group_26_pc2  group_26_pc3  group_26_pc4  group_26_pc5  \\\n0         -1.016482     -0.137339     -0.168235     -0.287223     -0.973681   \n1         -1.042950     -0.167090     -0.143400     -0.126721     -0.988604   \n2         -1.027246     -0.094688     -0.130670     -0.092504     -0.910300   \n3         -0.992870      0.071168     -0.077338      0.018613     -0.591582   \n4         -1.057164     -0.045856     -0.113084     -0.015578     -0.696855   \n...             ...           ...           ...           ...           ...   \n39739     -1.337490      0.231888     -0.029913      0.226638      0.193479   \n39740     -1.329558      0.117914     -0.136001     -0.012905      0.273652   \n39741     -1.268222      0.062836     -0.128262     -0.039988      0.011198   \n39742     -1.288870      0.116845     -0.065398      0.118060      0.022430   \n39743     -1.293931      0.041992     -0.044203      0.204347     -0.063132   \n\n       group_26_pc6  \n0          0.319253  \n1          0.274030  \n2          0.305771  \n3          0.145145  \n4          0.189270  \n...             ...  \n39739     -0.446107  \n39740     -0.664857  \n39741     -0.537303  \n39742     -0.489687  \n39743     -0.421077  \n\n[39744 rows x 874 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>V0241</th>\n      <th>V0242</th>\n      <th>V0244</th>\n      <th>V0295</th>\n      <th>V0301</th>\n      <th>V0650</th>\n      <th>V0661</th>\n      <th>V0965</th>\n      <th>...</th>\n      <th>group_29_pc3</th>\n      <th>group_29_pc4</th>\n      <th>group_29_pc5</th>\n      <th>group_29_pc6</th>\n      <th>group_26_pc1</th>\n      <th>group_26_pc2</th>\n      <th>group_26_pc3</th>\n      <th>group_26_pc4</th>\n      <th>group_26_pc5</th>\n      <th>group_26_pc6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.026310</td>\n      <td>-0.046308</td>\n      <td>0.056537</td>\n      <td>0.085118</td>\n      <td>-1.016482</td>\n      <td>-0.137339</td>\n      <td>-0.168235</td>\n      <td>-0.287223</td>\n      <td>-0.973681</td>\n      <td>0.319253</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.033793</td>\n      <td>0.022892</td>\n      <td>0.057257</td>\n      <td>-0.274694</td>\n      <td>-1.042950</td>\n      <td>-0.167090</td>\n      <td>-0.143400</td>\n      <td>-0.126721</td>\n      <td>-0.988604</td>\n      <td>0.274030</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.045547</td>\n      <td>-0.053404</td>\n      <td>0.044242</td>\n      <td>-0.013962</td>\n      <td>-1.027246</td>\n      <td>-0.094688</td>\n      <td>-0.130670</td>\n      <td>-0.092504</td>\n      <td>-0.910300</td>\n      <td>0.305771</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.050546</td>\n      <td>-0.019396</td>\n      <td>0.053363</td>\n      <td>-0.143665</td>\n      <td>-0.992870</td>\n      <td>0.071168</td>\n      <td>-0.077338</td>\n      <td>0.018613</td>\n      <td>-0.591582</td>\n      <td>0.145145</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.061628</td>\n      <td>-0.037183</td>\n      <td>0.058138</td>\n      <td>-0.096996</td>\n      <td>-1.057164</td>\n      <td>-0.045856</td>\n      <td>-0.113084</td>\n      <td>-0.015578</td>\n      <td>-0.696855</td>\n      <td>0.189270</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39739</th>\n      <td>827</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.560465</td>\n      <td>-0.072883</td>\n      <td>0.041725</td>\n      <td>-0.188920</td>\n      <td>-1.337490</td>\n      <td>0.231888</td>\n      <td>-0.029913</td>\n      <td>0.226638</td>\n      <td>0.193479</td>\n      <td>-0.446107</td>\n    </tr>\n    <tr>\n      <th>39740</th>\n      <td>827</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.568635</td>\n      <td>-0.022889</td>\n      <td>0.037029</td>\n      <td>-0.589832</td>\n      <td>-1.329558</td>\n      <td>0.117914</td>\n      <td>-0.136001</td>\n      <td>-0.012905</td>\n      <td>0.273652</td>\n      <td>-0.664857</td>\n    </tr>\n    <tr>\n      <th>39741</th>\n      <td>827</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.550188</td>\n      <td>-0.089338</td>\n      <td>0.122138</td>\n      <td>-0.246961</td>\n      <td>-1.268222</td>\n      <td>0.062836</td>\n      <td>-0.128262</td>\n      <td>-0.039988</td>\n      <td>0.011198</td>\n      <td>-0.537303</td>\n    </tr>\n    <tr>\n      <th>39742</th>\n      <td>827</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.545558</td>\n      <td>-0.138585</td>\n      <td>0.155958</td>\n      <td>-0.075894</td>\n      <td>-1.288870</td>\n      <td>0.116845</td>\n      <td>-0.065398</td>\n      <td>0.118060</td>\n      <td>0.022430</td>\n      <td>-0.489687</td>\n    </tr>\n    <tr>\n      <th>39743</th>\n      <td>827</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.561588</td>\n      <td>-0.172648</td>\n      <td>0.143120</td>\n      <td>0.132126</td>\n      <td>-1.293931</td>\n      <td>0.041992</td>\n      <td>-0.044203</td>\n      <td>0.204347</td>\n      <td>-0.063132</td>\n      <td>-0.421077</td>\n    </tr>\n  </tbody>\n</table>\n<p>39744 rows × 874 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tr_vl_split(train_df, num, seed):    \n    '''\n    train / validation split 함수\n    train 에 모든 label이 최소 한번은 등장 & train과 validation의 id는 겹치지 않도록 split함.\n    \n    train_df : train 데이터\n    num : label 당 몇개의 id를 뽑을 것이냐.\n    seed = random seed\n    \n    '''\n    \n    np.random.seed(seed)\n    \n    valid_id = []\n    vc = train[['id','label']].drop_duplicates()['label'].value_counts()\n    temp = list(vc[vc > num].index)\n    for a in temp:\n        id_list = list(train_df[train_df['label'] == a]['id'])\n        valid_id += random.sample(id_list,num)\n    \n    train_id = list(set(train_df['id']) - set(valid_id))\n    \n    x_tr_ = train[train['id'].isin(train_id)]\n    y_tr_ = train_label[train['id'].isin(train_id)]\n\n    x_vl_ = train[~train['id'].isin(train_id)]\n    y_vl_ = train_label[~train['id'].isin(train_id)]\n    \n    return x_tr_, y_tr_, x_vl_, y_vl_ ","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tr, y_tr, x_vl, y_vl = tr_vl_split(train, 3, seed = 1995)\n\nprint('train shape :',x_tr.shape)\nprint('validation shape :',x_vl.shape)\nprint('test shape :', test.shape)","execution_count":45,"outputs":[{"output_type":"stream","text":"train shape : (31152, 874)\nvalidation shape : (8592, 874)\ntest shape : (34560, 873)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nlgb_tr = lgb.Dataset(x_tr[var_model], label=y_tr)\nlgb_vl = lgb.Dataset(x_vl[var_model], label=y_vl)\n\nwatchlist_1 = [lgb_tr, lgb_vl]\nwatchlist_2 = [lgb_vl, lgb_tr]\n\nparams = {\n    \"objective\": \"multiclass\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 40,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"multiclass\",\n    \"num_class\" : 198\n}\n\nlgb_model = lgb.train(params, train_set=lgb_tr, num_boost_round=1000, valid_sets=watchlist_1, verbose_eval=100, early_stopping_rounds=100)\n\nprediction = pd.DataFrame(lgb_model.predict(test[var_model]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}
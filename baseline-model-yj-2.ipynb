{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/15th-data60sec/var_list.csv\n",
      "/kaggle/input/15th-data60sec/train_label.csv\n",
      "/kaggle/input/15th-data60sec/train_data.pickle/train_data.pickle\n",
      "/kaggle/input/15th-data60sec/test_data.pickle/test_data.pickle\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import random\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle('/kaggle/input/15th-data60sec/train_data.pickle/train_data.pickle')\n",
    "test = pd.read_pickle('/kaggle/input/15th-data60sec/test_data.pickle/test_data.pickle')\n",
    "train_label = train['label']\n",
    "\n",
    "var_list = list(pd.read_csv('/kaggle/input/15th-data60sec/var_list.csv')['var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = list(reversed(sorted(list(set(var_list) - set(train.columns[train.isna().any()].tolist() + test.columns[test.isna().any()].tolist())))))\n",
    "\n",
    "train = train.loc[(train['time'] >= 10),var_list].reset_index(drop=True)\n",
    "test = test.loc[(test['time'] >= 10),list(set(var_list) - set(['label']))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41400, 2545)\n",
      "(36000, 2544)\n"
     ]
    }
   ],
   "source": [
    "print(train[var_list].shape)\n",
    "print(test[list(set(var_list) - set(['label']))].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 2.27 s, total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = train.groupby('id').rolling(window = 5).mean().drop(columns = ['id']).reset_index().drop(columns = ['level_1']).dropna().reset_index(drop=True)\n",
    "train_label = train['label']\n",
    "train_id = train['id']\n",
    "\n",
    "test = test.groupby('id').rolling(window = 5).mean().drop(columns = ['id']).reset_index().drop(columns = ['level_1']).dropna().reset_index(drop=True)\n",
    "test_id = test['id']\n",
    "\n",
    "var_model = list(set(train.columns) & set(test.columns) - set(['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_vl_split(train_df, num, seed):    \n",
    "    '''\n",
    "    train / validation split 함수\n",
    "    train 에 모든 label이 최소 한번은 등장 & train과 validation의 id는 겹치지 않도록 split함.\n",
    "    \n",
    "    train_df : train 데이터\n",
    "    num : label 당 몇개의 id를 뽑을 것이냐.\n",
    "    seed = random seed\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    valid_id = []\n",
    "    vc = train[['id','label']].drop_duplicates()['label'].value_counts()\n",
    "    temp = list(vc[vc > num].index)\n",
    "    for a in temp:\n",
    "        id_list = list(train_df[train_df['label'] == a]['id'])\n",
    "        valid_id += random.sample(id_list,num)\n",
    "    \n",
    "    train_id = list(set(train_df['id']) - set(valid_id))\n",
    "    \n",
    "    x_tr_ = train[train['id'].isin(train_id)]\n",
    "    y_tr_ = train_label[train['id'].isin(train_id)]\n",
    "\n",
    "    x_vl_ = train[~train['id'].isin(train_id)]\n",
    "    y_vl_ = train_label[~train['id'].isin(train_id)]\n",
    "    \n",
    "    return x_tr_, y_tr_, x_vl_, y_vl_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (29624, 2545)\n",
      "validation shape : (8464, 2545)\n",
      "test shape : (33120, 2544)\n"
     ]
    }
   ],
   "source": [
    "x_tr, y_tr, x_vl, y_vl = tr_vl_split(train, 3, seed = 1995)\n",
    "\n",
    "print('train shape :',x_tr.shape)\n",
    "print('validation shape :',x_vl.shape)\n",
    "print('test shape :', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.0246187\tvalid_1's multi_logloss: 0.781002\n",
      "[200]\ttraining's multi_logloss: 0.0028939\tvalid_1's multi_logloss: 0.729679\n",
      "[300]\ttraining's multi_logloss: 0.00128082\tvalid_1's multi_logloss: 0.728472\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's multi_logloss: 0.00169826\tvalid_1's multi_logloss: 0.727662\n"
     ]
    }
   ],
   "source": [
    "lgb_tr = lgb.Dataset(x_tr[var_model], label=y_tr)\n",
    "lgb_vl = lgb.Dataset(x_vl[var_model], label=y_vl)\n",
    "\n",
    "watchlist_1 = [lgb_tr, lgb_vl]\n",
    "watchlist_2 = [lgb_vl, lgb_tr]\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 40,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"multiclass\",\n",
    "    \"num_class\" : 198\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(params, train_set=lgb_tr, num_boost_round=1000, valid_sets=watchlist_1, verbose_eval=100, early_stopping_rounds=100)\n",
    "\n",
    "prediction = pd.DataFrame(lgb_model.predict(test[var_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = datetime.now()\n",
    "submission_name = str(time_now)[:16] + '_submission.csv'\n",
    "sub = pd.concat([pd.DataFrame(test_id),prediction],axis=1).groupby('id').mean().reset_index()\n",
    "sub.to_csv(submission_name,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
